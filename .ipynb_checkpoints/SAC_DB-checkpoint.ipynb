{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftQNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3, log_std_min=-20, log_std_max=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.mean_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "        self.log_std_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        mean    = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
    "        \n",
    "        return mean, log_std\n",
    "    \n",
    "    def evaluate(self, state, epsilon=1e-6):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample()\n",
    "        action = torch.tanh(mean+ std*z.to(device))\n",
    "        log_prob = Normal(mean, std).log_prob(mean+ std*z.to(device)) - torch.log(1 - action.pow(2) + epsilon)\n",
    "        return action, log_prob, z, mean, log_std\n",
    "        \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample().to(device)\n",
    "        action = torch.tanh(mean + std*z)\n",
    "        \n",
    "        action  = action.cpu()#.detach().cpu().numpy()\n",
    "        return action[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        \n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedActions(gym.ActionWrapper):\n",
    "    def _action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "        \n",
    "        action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "        \n",
    "        action = 2 * (action - low) / (high - low) - 1\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAC(object):\n",
    "    \n",
    "    def __init__(self, state_dim, action_dim,env):\n",
    "        \n",
    "        self.action_dim = action_dim\n",
    "        self.state_dim  = state_dim\n",
    "        self.hidden_dim = 256\n",
    "\n",
    "        self.value_net        = ValueNetwork(self.state_dim, self.hidden_dim).to(device)\n",
    "        self.target_value_net = ValueNetwork(self.state_dim, self.hidden_dim).to(device)\n",
    "\n",
    "        self.soft_q_net1 = SoftQNetwork(self.state_dim, self.action_dim, self.hidden_dim).to(device)\n",
    "        self.soft_q_net2 = SoftQNetwork(self.state_dim, self.action_dim, self.hidden_dim).to(device)\n",
    "        self.policy_net = PolicyNetwork(self.state_dim, self.action_dim, self.hidden_dim).to(device)\n",
    "\n",
    "        for target_param, param in zip(self.target_value_net.parameters(), self.value_net.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "\n",
    "\n",
    "        self.value_criterion  = nn.MSELoss()\n",
    "        self.soft_q_criterion1 = nn.MSELoss()\n",
    "        self.soft_q_criterion2 = nn.MSELoss()\n",
    "\n",
    "        self.value_lr  = 3e-4\n",
    "        self.soft_q_lr = 3e-4\n",
    "        self.policy_lr = 3e-4\n",
    "\n",
    "        self.value_optimizer  = optim.Adam(self.value_net.parameters(), lr=self.value_lr)\n",
    "        self.soft_q_optimizer1 = optim.Adam(self.soft_q_net1.parameters(), lr=self.soft_q_lr)\n",
    "        self.soft_q_optimizer2 = optim.Adam(self.soft_q_net2.parameters(), lr=self.soft_q_lr)\n",
    "        self.policy_optimizer = optim.Adam(self.policy_net.parameters(), lr=self.policy_lr)\n",
    "\n",
    "\n",
    "        replay_buffer_size = 1000000\n",
    "        self.replay_buffer = ReplayBuffer(replay_buffer_size)\n",
    "    \n",
    "    def select_action(self,state):\n",
    "        return self.policy_net.get_action(state).detach()\n",
    "        \n",
    "        \n",
    "    def update(self, batch_size,gamma=0.99,soft_tau=1e-2,):\n",
    "        \n",
    "        state, action, reward, next_state, done = self.replay_buffer.sample(batch_size)\n",
    "\n",
    "        state      = torch.FloatTensor(state).to(device)\n",
    "        next_state = torch.FloatTensor(next_state).to(device)\n",
    "        action     = torch.FloatTensor(action).to(device)\n",
    "        reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "        done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "\n",
    "        predicted_q_value1 = self.soft_q_net1(state, action)\n",
    "        predicted_q_value2 = self.soft_q_net2(state, action)\n",
    "        predicted_value    = self.value_net(state)\n",
    "        new_action, log_prob, epsilon, mean, log_std = self.policy_net.evaluate(state)\n",
    "\n",
    "\n",
    "\n",
    "    # Training Q Function\n",
    "        target_value = self.target_value_net(next_state)\n",
    "        target_q_value = reward + (1 - done) * gamma * target_value\n",
    "        q_value_loss1 = self.soft_q_criterion1(predicted_q_value1, target_q_value.detach())\n",
    "        q_value_loss2 = self.soft_q_criterion2(predicted_q_value2, target_q_value.detach())\n",
    "\n",
    "\n",
    "        self.soft_q_optimizer1.zero_grad()\n",
    "        q_value_loss1.backward()\n",
    "        self.soft_q_optimizer1.step()\n",
    "        self.soft_q_optimizer2.zero_grad()\n",
    "        q_value_loss2.backward()\n",
    "        self.soft_q_optimizer2.step()  \n",
    "        \n",
    "    # Training Value Function\n",
    "        predicted_new_q_value = torch.min(self.soft_q_net1(state, new_action),self.soft_q_net2(state, new_action))\n",
    "        target_value_func = predicted_new_q_value - log_prob\n",
    "        value_loss = self.value_criterion(predicted_value, target_value_func.detach())\n",
    "\n",
    "\n",
    "        self.value_optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        self.value_optimizer.step()\n",
    "    # Training Policy Function\n",
    "        policy_loss = (log_prob - predicted_new_q_value).mean()\n",
    "\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.policy_optimizer.step()\n",
    "\n",
    "\n",
    "        for target_param, param in zip(self.target_value_net.parameters(), self.value_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    \"\"\"Carries out the environment steps and adds experiences to memory\"\"\"\n",
    "    \n",
    "    def __init__(self, env, agent):\n",
    "        \n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "#         self.replay_buffer = replay_buffer\n",
    "        self.obs = env.reset()\n",
    "        self.done = False\n",
    "        \n",
    "    def next_step(self, episode_timesteps, noise=0.1):\n",
    "        \n",
    "        action = self.agent.select_action(self.obs)\n",
    "        \n",
    "\n",
    "        # Perform action\n",
    "        # TODO: Clean up get action \n",
    "        new_obs, reward, done, _ = self.env.step(action.numpy()) \n",
    "        done_bool = 0 if episode_timesteps + 1 == 200 else float(done)\n",
    "    \n",
    "        # Store data in replay buffer\n",
    "#         replay_buffer.add((self.obs, new_obs, action, reward, done_bool))\n",
    "        self.agent.replay_buffer.push(self.obs, action, reward, new_obs, done_bool)\n",
    "        \n",
    "        self.obs = new_obs\n",
    "        \n",
    "        if done:\n",
    "            self.obs = self.env.reset()\n",
    "            done = False\n",
    "            \n",
    "            return reward, True\n",
    "        \n",
    "        return reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe(env, agent, observation_steps):\n",
    "    \"\"\"run episodes while taking random actions and filling replay_buffer\n",
    "    \n",
    "        Args:\n",
    "            env (env): gym environment\n",
    "            replay_buffer(ReplayBuffer): buffer to store experience replay\n",
    "            observation_steps (int): how many steps to observe for\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    time_steps = 0\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while time_steps < observation_steps:\n",
    "        action = env.action_space.sample()\n",
    "        new_obs, reward, done, _ = env.step(action)\n",
    "\n",
    "        agent.replay_buffer.push(obs, action, reward, new_obs, done)\n",
    "\n",
    "        obs = new_obs\n",
    "        time_steps += 1\n",
    "\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "\n",
    "        print(\"\\rPopulating Buffer {}/{}.\".format(time_steps, observation_steps), end=\"\")\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, test_env):\n",
    "    \"\"\"Train the agent for exploration steps\n",
    "    \n",
    "        Args:\n",
    "            agent (Agent): agent to use\n",
    "            env (environment): gym environment\n",
    "            writer (SummaryWriter): tensorboard writer\n",
    "            exploration (int): how many training steps to run\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    total_timesteps = 0\n",
    "    timesteps_since_eval = 0\n",
    "    episode_num = 0\n",
    "    episode_reward = 0\n",
    "    episode_timesteps = 0\n",
    "    done = False \n",
    "    obs = env.reset()\n",
    "    evaluations = []\n",
    "    rewards = []\n",
    "    best_avg = -2000\n",
    "    \n",
    "    writer = SummaryWriter(comment=\"-TD3_Baseline_HalfCheetah\")\n",
    "    \n",
    "    while total_timesteps < EXPLORATION:\n",
    "    \n",
    "        if done: \n",
    "\n",
    "            if total_timesteps != 0: \n",
    "                rewards.append(episode_reward)\n",
    "                \n",
    "                if total_timesteps % 1000 == 0:\n",
    "                    plot(len(rewards), rewards)\n",
    "                \n",
    "                avg_reward = np.mean(rewards[-100:])\n",
    "                \n",
    "                writer.add_scalar(\"avg_reward\", avg_reward, total_timesteps)\n",
    "                writer.add_scalar(\"reward_step\", reward, total_timesteps)\n",
    "                writer.add_scalar(\"episode_reward\", episode_reward, total_timesteps)\n",
    "                \n",
    "                print(\"\\rTotal T: {:d} Episode Num: {:d} Reward: {:f} Avg Reward: {:f}\".format(\n",
    "                    total_timesteps, episode_num, episode_reward, avg_reward), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "\n",
    "                if avg_reward >= REWARD_THRESH:\n",
    "                    break\n",
    "\n",
    "#                 agent.update(replay_buffer, episode_timesteps, BATCH_SIZE, GAMMA, TAU, NOISE, NOISE_CLIP, POLICY_FREQUENCY)\n",
    "#                 agent.update(128)\n",
    "\n",
    "                episode_reward = 0\n",
    "                episode_timesteps = 0\n",
    "                episode_num += 1 \n",
    "\n",
    "        reward, done = runner.next_step(episode_timesteps)\n",
    "        episode_reward += reward\n",
    "\n",
    "        episode_timesteps += 1\n",
    "        total_timesteps += 1\n",
    "        timesteps_since_eval += 1\n",
    "        \n",
    "        agent.update(128)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = \"Pendulum-v0\"\n",
    "SEED = 0\n",
    "OBSERVATION = 1000\n",
    "EXPLORATION = 40000\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "TAU = 0.005\n",
    "NOISE = 0.2\n",
    "NOISE_CLIP = 0.5\n",
    "EXPLORE_NOISE = 0.1\n",
    "POLICY_FREQUENCY = 2\n",
    "EVAL_FREQUENCY = 5000\n",
    "REWARD_THRESH = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = NormalizedActions(gym.make(ENV))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seeds\n",
    "env.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0] \n",
    "max_action = float(env.action_space.high[0])\n",
    "\n",
    "agent = SAC(state_dim, action_dim, env)\n",
    "\n",
    "# replay_buffer = ReplayBuffer()\n",
    "\n",
    "runner = Runner(env, agent)\n",
    "\n",
    "total_timesteps = 0\n",
    "timesteps_since_eval = 0\n",
    "episode_num = 0\n",
    "done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating Buffer 164/1000."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donal/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class '__main__.NormalizedActions'> doesn't implement 'action' method. Maybe it implements deprecated '_action' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating Buffer 1000/1000."
     ]
    }
   ],
   "source": [
    "# Populate replay buffer\n",
    "observe(env, agent, OBSERVATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T: 7800 Episode Num: 38 Reward: -121.687135 Avg Reward: -722.417718"
     ]
    }
   ],
   "source": [
    "# Train agent\n",
    "train(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
